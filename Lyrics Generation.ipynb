{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lyrics Generation with LSTM"
      ],
      "metadata": {
        "id": "sQ3geZtt4kXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string, os\n",
        "import keras\n",
        "import random\n",
        "import io\n",
        "import sys\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "bGT5VbN74cwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we need to find a proper dataset and read it. The dataset I used is from here:\n",
        "\n",
        "https://marianaossilva.github.io/DSW2019/index.html\n",
        "\n",
        "We read the csv file using the read_csv of pandas. Drop the NaN rows and show the head of it."
      ],
      "metadata": {
        "id": "oXQxZRgUFZbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lyrs = pd.read_csv('lyrics.csv', sep=\"\\t\")\n",
        "print(lyrs.describe())\n",
        "lyrs = lyrs.dropna()\n",
        "lyrs.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "ghJuWJ6Fi9Sh",
        "outputId": "4e751584-55ab-41c9-a33d-7bdf8b28f418"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       song_id              lyrics\n",
            "count                    20404               19663\n",
            "unique                   20404               19026\n",
            "top     3e9HZxeyfWwjeyPAMmWSSQ  ['[Instrumental]']\n",
            "freq                         1                  55\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  song_id                                             lyrics\n",
              "0  3e9HZxeyfWwjeyPAMmWSSQ  ['[Verse 1]\\nThought I\\'d end up with Sean\\nBu...\n",
              "1  5p7ujcrUXASCNwRaWNHR1C  [\"[Verse 1]\\nFound you when your heart was bro...\n",
              "2  2xLMifQCjDGFmkHkpNLD9h  ['[Part I]\\n\\n[Intro: Drake]\\nAstro, yeah\\nSun...\n",
              "3  3KkXRkHbMCARz0aVfEt68P                                                NaN\n",
              "4  1rqqCSm0Qe4I9rUvWncaom  [\"[Intro]\\nHigh, high hopes\\n\\n[Chorus]\\nHad t..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0626b669-a033-40a1-8b83-e7988894db6c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>song_id</th>\n",
              "      <th>lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3e9HZxeyfWwjeyPAMmWSSQ</td>\n",
              "      <td>['[Verse 1]\\nThought I\\'d end up with Sean\\nBu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5p7ujcrUXASCNwRaWNHR1C</td>\n",
              "      <td>[\"[Verse 1]\\nFound you when your heart was bro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2xLMifQCjDGFmkHkpNLD9h</td>\n",
              "      <td>['[Part I]\\n\\n[Intro: Drake]\\nAstro, yeah\\nSun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3KkXRkHbMCARz0aVfEt68P</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1rqqCSm0Qe4I9rUvWncaom</td>\n",
              "      <td>[\"[Intro]\\nHigh, high hopes\\n\\n[Chorus]\\nHad t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0626b669-a033-40a1-8b83-e7988894db6c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0626b669-a033-40a1-8b83-e7988894db6c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0626b669-a033-40a1-8b83-e7988894db6c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to clean the data first. As we can see, the lyrics contains some meta labelings. So we can split every lyric into the intro, verses, and the chorus. We choose the first four verses and the chorus for this task. Then we join the parts to have a single text.\n",
        "\n",
        "We use translators to do this. \"maketrans\" method is a method that creates a one to one mapping of a character to its translation/replacement.\n",
        "It creates a Unicode representation of each character for translation.\n",
        "This translation mapping is then used for replacing a character to its mapped character when used in translate() method."
      ],
      "metadata": {
        "id": "VvpTuLRyGHCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text(data):\n",
        "   text = data['lyrics']\n",
        "   sections = text.split('\\\\n\\\\n')\n",
        "   keys = {'Verse 1': np.nan,'Verse 2':np.nan,'Verse 3':np.nan,'Verse 4':np.nan, 'Chorus':np.nan}\n",
        "   lyrics = str()\n",
        "   single_text = []\n",
        "   res = {}\n",
        "   for s in sections:\n",
        "       key = s[s.find('[') + 1:s.find(']')].strip()\n",
        "       if ':' in key:\n",
        "           key = key[:key.find(':')]\n",
        "\n",
        "       if key in keys:\n",
        "           single_text += [x.lower().replace('(','').replace(')','').translate(translator) for x in s[s.find(']')+1:].split('\\\\n') if len(data) > 1]\n",
        "          \n",
        "       res['single_text'] =  ' \\n '.join(single_text)\n",
        "\n",
        "   return pd.Series(res)\n",
        "\n",
        "translator = str.maketrans('', '', string.punctuation)\n",
        "lyrs = lyrs.join(lyrs.apply(split_text, axis=1))\n",
        "lyrs.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8kzDxs5BiANt",
        "outputId": "f5b24572-d6be-44aa-e7a4-b35b52e33f6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  song_id                                             lyrics  \\\n",
              "0  3e9HZxeyfWwjeyPAMmWSSQ  ['[Verse 1]\\nThought I\\'d end up with Sean\\nBu...   \n",
              "1  5p7ujcrUXASCNwRaWNHR1C  [\"[Verse 1]\\nFound you when your heart was bro...   \n",
              "2  2xLMifQCjDGFmkHkpNLD9h  ['[Part I]\\n\\n[Intro: Drake]\\nAstro, yeah\\nSun...   \n",
              "4  1rqqCSm0Qe4I9rUvWncaom  [\"[Intro]\\nHigh, high hopes\\n\\n[Chorus]\\nHad t...   \n",
              "5  0bYg9bo50gSsH3LtXe2SQn  [\"[Intro]\\nI-I-I don't want a lot for Christma...   \n",
              "\n",
              "                                         single_text  \n",
              "0  thank you next next \\n thank you next next \\n ...  \n",
              "1  tell me hows it feel sittin up there \\n feelin...  \n",
              "2  woo made this here with all the ice on in the ...  \n",
              "4  had to have high high hopes for a living \\n sh...  \n",
              "5  i dont want a lot for christmas \\n there is ju...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06c876d9-4c60-4882-83aa-7ae72f7c833c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>song_id</th>\n",
              "      <th>lyrics</th>\n",
              "      <th>single_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3e9HZxeyfWwjeyPAMmWSSQ</td>\n",
              "      <td>['[Verse 1]\\nThought I\\'d end up with Sean\\nBu...</td>\n",
              "      <td>thank you next next \\n thank you next next \\n ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5p7ujcrUXASCNwRaWNHR1C</td>\n",
              "      <td>[\"[Verse 1]\\nFound you when your heart was bro...</td>\n",
              "      <td>tell me hows it feel sittin up there \\n feelin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2xLMifQCjDGFmkHkpNLD9h</td>\n",
              "      <td>['[Part I]\\n\\n[Intro: Drake]\\nAstro, yeah\\nSun...</td>\n",
              "      <td>woo made this here with all the ice on in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1rqqCSm0Qe4I9rUvWncaom</td>\n",
              "      <td>[\"[Intro]\\nHigh, high hopes\\n\\n[Chorus]\\nHad t...</td>\n",
              "      <td>had to have high high hopes for a living \\n sh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0bYg9bo50gSsH3LtXe2SQn</td>\n",
              "      <td>[\"[Intro]\\nI-I-I don't want a lot for Christma...</td>\n",
              "      <td>i dont want a lot for christmas \\n there is ju...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06c876d9-4c60-4882-83aa-7ae72f7c833c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-06c876d9-4c60-4882-83aa-7ae72f7c833c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-06c876d9-4c60-4882-83aa-7ae72f7c833c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to  use the data, I converted the csv rows into a single text string by using the join method."
      ],
      "metadata": {
        "id": "SU7fyE9i4u4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "single_text = list(lyrs['single_text'])\n",
        "  \n",
        "# converting list into string and then joining it with space\n",
        "b = ' '.join(str(e) for e in single_text)"
      ],
      "metadata": {
        "id": "yvPB6xgZkYEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is so big and to fit a model with this heavy dataset requires GPUs to train faster and doesn't face any RAM errors. Thus, I used 100000 records of the data to train my model. However, the model would definitely generate better and more reasonable lyrics if we use the whole dataset.\n",
        "\n",
        "Moreover, if we have both capital and lowercase letters, the model should learn all of them, while it is not necessary to learn capital letters. Thus, we convert all the lyrics to lower letters."
      ],
      "metadata": {
        "id": "wjMvHO430c0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text = b[0:100000]\n",
        "raw_text = raw_text.lower()"
      ],
      "metadata": {
        "id": "VJIe38l2FUaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since it is tough for the machine to learn asciis, we create a dictionary from the existing characters to integers and map them. So in order to obtain the existing characters in the dataset, we create a set from the data we have. This model will create words and generate lyrics by putting the characters together."
      ],
      "metadata": {
        "id": "PMW9LVYg1oQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print(\"Total Vocab: \", n_vocab)"
      ],
      "metadata": {
        "id": "qUWnOSvGFUuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we want to prepare the data for training our model. There are lots of methods to split the text and give it to  the network. Here we split the lyrics into sequences of fixed character length (here 100). The length is arbitrary. Another method could be splitting the lyrics by the sentences, or different verses.\n",
        "\n",
        "When creating sequences, we slide this 100 character length window along the whole text at a time. Each training pattern of the network comprises 100 time steps of one character (X) followed by one character output (y). In this way, \n",
        "the network will learn each charater one by one. However the first 100 characters will not be learned by the model."
      ],
      "metadata": {
        "id": "VjC40L-twqXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        " seq_in = raw_text[i:i + seq_length]\n",
        " seq_out = raw_text[i + seq_length]\n",
        " dataX.append([char_to_int[char] for char in seq_in])\n",
        " dataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print(\"Total Patterns: \", n_patterns)"
      ],
      "metadata": {
        "id": "NXCue8Zzy90J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The input of LSTM has a particular format which we need to reshape our data to create it. We will reshape it into \"[samples, time steps, features]\" format.\n",
        "\n",
        "Then in order to normalize it, we divide it with the number of vocabularies that we have. And remember, the vocabularies were the unique set that the model should learn.\n",
        "\n",
        "Then since we will generate characters, we use one hot encoding for the output variable. So we predict the character with the most probability."
      ],
      "metadata": {
        "id": "Wg-O4qX0JgGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "X = X / float(n_vocab)\n",
        "y = to_categorical(dataY)"
      ],
      "metadata": {
        "id": "853JlpaGzAtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we would define the LSTM model. The output dimension is set as 256. Then we use dropout method with the probablity of 20%. And another LSTM layer and one more dropout. At the end, there's a softmax activation layer with the Adam optimizer."
      ],
      "metadata": {
        "id": "bFrwJm6DFILW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "Q31eyxJ8zF6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now we would want to save the network weights for each epoc and in the generating mode, we would use the weights with minimum loss."
      ],
      "metadata": {
        "id": "-INI9x9ZnUxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "metadata": {
        "id": "huQdF8jXzILF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we would fit the model!\n",
        "With 50 epocs and batch size of 64."
      ],
      "metadata": {
        "id": "H-vPZaHlHFu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=50, batch_size=64, callbacks=callbacks_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHz7VoPplNpX",
        "outputId": "cd1bb782-4871-465f-ade3-1eefbfec8e10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10451820\n",
            "Total Characters:  100000\n",
            "Total Vocab:  43\n",
            "Total Patterns:  99900\n",
            "Epoch 1/50\n",
            "1561/1561 [==============================] - ETA: 0s - loss: 2.6637\n",
            "Epoch 1: loss improved from inf to 2.66368, saving model to weights-improvement-01-2.6637-bigger.hdf5\n",
            "1561/1561 [==============================] - 38s 18ms/step - loss: 2.6637\n",
            "Epoch 2/50\n",
            "1561/1561 [==============================] - ETA: 0s - loss: 2.3402\n",
            "Epoch 2: loss improved from 2.66368 to 2.34024, saving model to weights-improvement-02-2.3402-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 2.3402\n",
            "Epoch 3/50\n",
            "1560/1561 [============================>.] - ETA: 0s - loss: 2.1580\n",
            "Epoch 3: loss improved from 2.34024 to 2.15794, saving model to weights-improvement-03-2.1579-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 2.1579\n",
            "Epoch 4/50\n",
            "1561/1561 [==============================] - ETA: 0s - loss: 2.0141\n",
            "Epoch 4: loss improved from 2.15794 to 2.01414, saving model to weights-improvement-04-2.0141-bigger.hdf5\n",
            "1561/1561 [==============================] - 29s 19ms/step - loss: 2.0141\n",
            "Epoch 5/50\n",
            "1561/1561 [==============================] - ETA: 0s - loss: 1.9039\n",
            "Epoch 5: loss improved from 2.01414 to 1.90386, saving model to weights-improvement-05-1.9039-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 1.9039\n",
            "Epoch 6/50\n",
            "1560/1561 [============================>.] - ETA: 0s - loss: 1.8070\n",
            "Epoch 6: loss improved from 1.90386 to 1.80695, saving model to weights-improvement-06-1.8070-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 1.8070\n",
            "Epoch 7/50\n",
            "1559/1561 [============================>.] - ETA: 0s - loss: 1.7236\n",
            "Epoch 7: loss improved from 1.80695 to 1.72343, saving model to weights-improvement-07-1.7234-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 1.7234\n",
            "Epoch 8/50\n",
            "1561/1561 [==============================] - ETA: 0s - loss: 1.6534\n",
            "Epoch 8: loss improved from 1.72343 to 1.65340, saving model to weights-improvement-08-1.6534-bigger.hdf5\n",
            "1561/1561 [==============================] - 29s 19ms/step - loss: 1.6534\n",
            "Epoch 9/50\n",
            "1560/1561 [============================>.] - ETA: 0s - loss: 1.5831\n",
            "Epoch 9: loss improved from 1.65340 to 1.58342, saving model to weights-improvement-09-1.5834-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 1.5834\n",
            "Epoch 10/50\n",
            "1559/1561 [============================>.] - ETA: 0s - loss: 1.5203\n",
            "Epoch 10: loss improved from 1.58342 to 1.52036, saving model to weights-improvement-10-1.5204-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 1.5204\n",
            "Epoch 11/50\n",
            "1560/1561 [============================>.] - ETA: 0s - loss: 1.4685\n",
            "Epoch 11: loss improved from 1.52036 to 1.46856, saving model to weights-improvement-11-1.4686-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 1.4686\n",
            "Epoch 12/50\n",
            "1559/1561 [============================>.] - ETA: 0s - loss: 1.4080\n",
            "Epoch 12: loss improved from 1.46856 to 1.40792, saving model to weights-improvement-12-1.4079-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 1.4079\n",
            "Epoch 13/50\n",
            "1560/1561 [============================>.] - ETA: 0s - loss: 1.3598\n",
            "Epoch 13: loss improved from 1.40792 to 1.36007, saving model to weights-improvement-13-1.3601-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 1.3601\n",
            "Epoch 14/50\n",
            "1559/1561 [============================>.] - ETA: 0s - loss: 1.3218\n",
            "Epoch 14: loss improved from 1.36007 to 1.32187, saving model to weights-improvement-14-1.3219-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 1.3219\n",
            "Epoch 15/50\n",
            "1560/1561 [============================>.] - ETA: 0s - loss: 1.2745\n",
            "Epoch 15: loss improved from 1.32187 to 1.27450, saving model to weights-improvement-15-1.2745-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 1.2745\n",
            "Epoch 16/50\n",
            "1560/1561 [============================>.] - ETA: 0s - loss: 1.2411\n",
            "Epoch 16: loss improved from 1.27450 to 1.24109, saving model to weights-improvement-16-1.2411-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 1.2411\n",
            "Epoch 17/50\n",
            "1561/1561 [==============================] - ETA: 0s - loss: 1.2060\n",
            "Epoch 17: loss improved from 1.24109 to 1.20596, saving model to weights-improvement-17-1.2060-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 1.2060\n",
            "Epoch 18/50\n",
            "1559/1561 [============================>.] - ETA: 0s - loss: 1.1770\n",
            "Epoch 18: loss improved from 1.20596 to 1.17714, saving model to weights-improvement-18-1.1771-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 1.1771\n",
            "Epoch 19/50\n",
            "1561/1561 [==============================] - ETA: 0s - loss: 1.1517\n",
            "Epoch 19: loss improved from 1.17714 to 1.15172, saving model to weights-improvement-19-1.1517-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 1.1517\n",
            "Epoch 20/50\n",
            "1559/1561 [============================>.] - ETA: 0s - loss: 1.1195\n",
            "Epoch 20: loss improved from 1.15172 to 1.11977, saving model to weights-improvement-20-1.1198-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 1.1198\n",
            "Epoch 21/50\n",
            "1561/1561 [==============================] - ETA: 0s - loss: 1.1041\n",
            "Epoch 21: loss improved from 1.11977 to 1.10407, saving model to weights-improvement-21-1.1041-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 1.1041\n",
            "Epoch 22/50\n",
            "1560/1561 [============================>.] - ETA: 0s - loss: 1.0788\n",
            "Epoch 22: loss improved from 1.10407 to 1.07877, saving model to weights-improvement-22-1.0788-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 1.0788\n",
            "Epoch 23/50\n",
            "1561/1561 [==============================] - ETA: 0s - loss: 1.0557\n",
            "Epoch 23: loss improved from 1.07877 to 1.05567, saving model to weights-improvement-23-1.0557-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 1.0557\n",
            "Epoch 24/50\n",
            "1561/1561 [==============================] - ETA: 0s - loss: 1.0491\n",
            "Epoch 24: loss improved from 1.05567 to 1.04909, saving model to weights-improvement-24-1.0491-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 1.0491\n",
            "Epoch 25/50\n",
            "1560/1561 [============================>.] - ETA: 0s - loss: 1.0231\n",
            "Epoch 25: loss improved from 1.04909 to 1.02318, saving model to weights-improvement-25-1.0232-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 1.0232\n",
            "Epoch 26/50\n",
            "1559/1561 [============================>.] - ETA: 0s - loss: 1.0146\n",
            "Epoch 26: loss improved from 1.02318 to 1.01441, saving model to weights-improvement-26-1.0144-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 1.0144\n",
            "Epoch 27/50\n",
            "1559/1561 [============================>.] - ETA: 0s - loss: 1.0001\n",
            "Epoch 27: loss improved from 1.01441 to 1.00031, saving model to weights-improvement-27-1.0003-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 1.0003\n",
            "Epoch 28/50\n",
            "1560/1561 [============================>.] - ETA: 0s - loss: 0.9813\n",
            "Epoch 28: loss improved from 1.00031 to 0.98121, saving model to weights-improvement-28-0.9812-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 0.9812\n",
            "Epoch 29/50\n",
            "1561/1561 [==============================] - ETA: 0s - loss: 0.9697\n",
            "Epoch 29: loss improved from 0.98121 to 0.96970, saving model to weights-improvement-29-0.9697-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 0.9697\n",
            "Epoch 30/50\n",
            "1561/1561 [==============================] - ETA: 0s - loss: 0.9585\n",
            "Epoch 30: loss improved from 0.96970 to 0.95847, saving model to weights-improvement-30-0.9585-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 0.9585\n",
            "Epoch 31/50\n",
            "1561/1561 [==============================] - ETA: 0s - loss: 0.9488\n",
            "Epoch 31: loss improved from 0.95847 to 0.94883, saving model to weights-improvement-31-0.9488-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 0.9488\n",
            "Epoch 32/50\n",
            "1559/1561 [============================>.] - ETA: 0s - loss: 0.9361\n",
            "Epoch 32: loss improved from 0.94883 to 0.93618, saving model to weights-improvement-32-0.9362-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 0.9362\n",
            "Epoch 33/50\n",
            "1561/1561 [==============================] - ETA: 0s - loss: 0.9284\n",
            "Epoch 33: loss improved from 0.93618 to 0.92840, saving model to weights-improvement-33-0.9284-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 0.9284\n",
            "Epoch 34/50\n",
            "1561/1561 [==============================] - ETA: 0s - loss: 0.9213\n",
            "Epoch 34: loss improved from 0.92840 to 0.92127, saving model to weights-improvement-34-0.9213-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 0.9213\n",
            "Epoch 35/50\n",
            "1559/1561 [============================>.] - ETA: 0s - loss: 0.9126\n",
            "Epoch 35: loss improved from 0.92127 to 0.91265, saving model to weights-improvement-35-0.9126-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 0.9126\n",
            "Epoch 36/50\n",
            "1561/1561 [==============================] - ETA: 0s - loss: 0.9060\n",
            "Epoch 36: loss improved from 0.91265 to 0.90599, saving model to weights-improvement-36-0.9060-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 0.9060\n",
            "Epoch 37/50\n",
            "1561/1561 [==============================] - ETA: 0s - loss: 0.8948\n",
            "Epoch 37: loss improved from 0.90599 to 0.89476, saving model to weights-improvement-37-0.8948-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 0.8948\n",
            "Epoch 38/50\n",
            "1561/1561 [==============================] - ETA: 0s - loss: 0.8870\n",
            "Epoch 38: loss improved from 0.89476 to 0.88701, saving model to weights-improvement-38-0.8870-bigger.hdf5\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 0.8870\n",
            "Epoch 39/50\n",
            "1559/1561 [============================>.] - ETA: 0s - loss: 2.9310\n",
            "Epoch 39: loss did not improve from 0.88701\n",
            "1561/1561 [==============================] - 29s 19ms/step - loss: 2.9305\n",
            "Epoch 40/50\n",
            "1560/1561 [============================>.] - ETA: 0s - loss: 2.5476\n",
            "Epoch 40: loss did not improve from 0.88701\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 2.5478\n",
            "Epoch 41/50\n",
            "1561/1561 [==============================] - ETA: 0s - loss: 2.3443\n",
            "Epoch 41: loss did not improve from 0.88701\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 2.3443\n",
            "Epoch 42/50\n",
            "1560/1561 [============================>.] - ETA: 0s - loss: 2.7060\n",
            "Epoch 42: loss did not improve from 0.88701\n",
            "1561/1561 [==============================] - 29s 19ms/step - loss: 2.7061\n",
            "Epoch 43/50\n",
            "1561/1561 [==============================] - ETA: 0s - loss: 2.8283\n",
            "Epoch 43: loss did not improve from 0.88701\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 2.8283\n",
            "Epoch 44/50\n",
            "1559/1561 [============================>.] - ETA: 0s - loss: 2.7622\n",
            "Epoch 44: loss did not improve from 0.88701\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 2.7622\n",
            "Epoch 45/50\n",
            "1560/1561 [============================>.] - ETA: 0s - loss: 2.6982\n",
            "Epoch 45: loss did not improve from 0.88701\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 2.6982\n",
            "Epoch 46/50\n",
            "1559/1561 [============================>.] - ETA: 0s - loss: 2.6351\n",
            "Epoch 46: loss did not improve from 0.88701\n",
            "1561/1561 [==============================] - 30s 19ms/step - loss: 2.6351\n",
            "Epoch 47/50\n",
            "1561/1561 [==============================] - ETA: 0s - loss: 2.5920\n",
            "Epoch 47: loss did not improve from 0.88701\n",
            "1561/1561 [==============================] - 29s 19ms/step - loss: 2.5920\n",
            "Epoch 48/50\n",
            "1560/1561 [============================>.] - ETA: 0s - loss: 2.5648\n",
            "Epoch 48: loss did not improve from 0.88701\n",
            "1561/1561 [==============================] - 29s 19ms/step - loss: 2.5648\n",
            "Epoch 49/50\n",
            "1561/1561 [==============================] - ETA: 0s - loss: 2.5414\n",
            "Epoch 49: loss did not improve from 0.88701\n",
            "1561/1561 [==============================] - 29s 19ms/step - loss: 2.5414\n",
            "Epoch 50/50\n",
            "1561/1561 [==============================] - ETA: 0s - loss: 2.5276\n",
            "Epoch 50: loss did not improve from 0.88701\n",
            "1561/1561 [==============================] - 29s 19ms/step - loss: 2.5276\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6917f85730>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the model is trained, we want to generate the lyrics. The only change to make the text generation script from the previous sections is in the specification of the network topology. We have to define from which file we want to seed the network weights. We choose the networks weights that had the minimum amount of loss. The rest is the same."
      ],
      "metadata": {
        "id": "J3NXqi3eloB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))"
      ],
      "metadata": {
        "id": "NorZP9guyfaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here now we load the weights with minimum loss to our model and then we will compile it."
      ],
      "metadata": {
        "id": "xwQglSUTL-wd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"weights-improvement-38-0.8870-bigger.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "Kd95bR9Gyhdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here now we want to generate lyrics and actually predict the next character. One way to do so is to start from a random sequence as a pattern, predict the next character, and trim the first character of the pattern. We limit this process by giving a sequence number (Here for example 2000). It means that we want a prediction with 2000 character long.  We use a random seed as the start of the our pattern."
      ],
      "metadata": {
        "id": "yBKIADF-hua-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = np.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print(\"Seed:\")\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
      ],
      "metadata": {
        "id": "N9nhORQ7huyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(2000):\n",
        "\tx = np.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = np.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print(\"\\nDone.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyeyJW05lVAD",
        "outputId": "3595bd13-aefd-43db-82fc-380aad51c15f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Characters:  100000\n",
            "Total Vocab:  43\n",
            "Total Patterns:  99900\n",
            "Seed:\n",
            "\" k into the room \n",
            " im speechless \n",
            " it started when you said hello \n",
            " just did something to me \n",
            " and iv \"\n",
            " wpu think i am the better one \n",
            " i was sno gone now a nigga thoe \n",
            " when you smine i see the sun sink down on a coast out in troone \n",
            " i was at the bottom the christmas tree \n",
            " ie shere is wou that you count my cass \n",
            " i could lie say i like it like that like it like that \n",
            " i just wanna stay foo tie siie im the dark \n",
            " cause i got a lot of cars they all up to so i can live i reel it in the dhen \n",
            " and there niggas talk le shink i am the better one \n",
            " i was soo gon and i went flobal \n",
            " its the most wonderful time of the year \n",
            " there she soueh the word \n",
            " i was on the corner with the stier \n",
            " got a seoole bou the street \n",
            " but i dont want to let you down let you down \n",
            " woulda gave you anything woulda gave you everything \n",
            " ohoh \n",
            " i seen you oh the casker \n",
            " tather be with you and all your bullshit \n",
            " id rather be with you and all your bullshit \n",
            " id rather be with you and all your bullshit \n",
            " id rather be with you and all your bullshit \n",
            " id rather be with you and all your bullshit \n",
            " id rather be with you and all your bullshit \n",
            " id rather be with you and all your bullshit \n",
            " id rather be with you and all your bullshit \n",
            " id rather be with you and all your bullshit \n",
            " id rather be with you and all your bullshit \n",
            " id rather be with you and all your bullshit \n",
            " id rather be with you and all your bullshit \n",
            " id rather be with you and all your bullshit \n",
            " id rather be with you and all your bullshit \n",
            " id rather be with you and all your bullshit \n",
            " id rather be with you and all your bullshit \n",
            " id rather be with you and all your bullshit \n",
            " id rather be with you and all your bullshit \n",
            " id rather be with you and all your bullshit \n",
            " id rather be with you and all your bullshit \n",
            " id rather be with you and all your bullshit \n",
            " id rather be with you and all your bullshit \n",
            " id rather be with you and all your bullshit \n",
            " id rather be with you and all your bullshit \n",
            " id rather be with you and all your bullshit \n",
            " id rather be with you and all your bullshit \n",
            " id rather be with you and all your bullshit \n",
            " id rathe\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see above, the generated text is not perfect. However, there are some characters that create meaningful words (i.e. corner, with, dark, like) and also some of the full sentences make sense and has meaning (i.e. id rather be with you and all your bullshit, but i dont want to let you down). On the other hand, it is not perfect and it needs to be improved.\n",
        "\n",
        "Next idea was using GAN architecture and LSTM to generate text."
      ],
      "metadata": {
        "id": "CKfjPPqk6yus"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lyrics generation using GAN architecture has some problems. Since text is a discrete data (unlike pictures) we have to change some methods in GAN.\n",
        "In RNN, at every time step, the RNN takes the previously generated text and the previous hidden state as an input and generate the next hidden state. \n",
        "Then the hidden state is passed through a linear layer and a softmax layer to generate the next word.\n",
        "\n",
        "So RNN is trained to predict the next word in a sentence at each time step.\n",
        "Then we back propagate the cross entropy loss between the softmax output and the one hot vector.\n",
        "\n",
        "Now, consider this RNN-based generator to be the generator network in a GAN. Here, the latent vector z is the input hidden state h⁰ of the RNN, and the generator output G(z) is the sentence output by the RNN. The difference here, is that instead of training the RNN to minimize cross-entropy loss with respect to target one-hot vectors, we will be training it to increase the probability of the discriminator network classifying the sentence as “real”. The objective now is to minimize 1 - D(G(z)).\n",
        "\n",
        "We know that while we are decoding using RNN, at every time step we choose the next word by picking the word with the maximum probability from the output of the softmax function. This “picking” operation is non-differentiable.\n",
        "\n",
        "It’s an issue because, in order to train the generator to minimize 1 - D(G(z)), we need to feed the output of the generator to the discriminator and back-propagate the corresponding loss of the discriminator. For these gradients to reach the generator, they have to go through the non-differentiable “picking” operation at the output of the generator. This is problematic as back-propagation relies on the differentiability of all the layers in the network.\n",
        "\n",
        "However this is perfectly feasible when the generated data is continuous, such as images. That's why GANs are so successful in Vision tasks and those with image as their data.\n",
        "\n",
        "In order to fix this problem, they came up with different ideas.\n",
        "1. Reinforcement Learning-based solutions\n",
        "2. The Gumbel-Softmax approximation which is a continuous approximation of the softmax function\n",
        "3. Using Auto-encoders\n",
        "\n",
        "Each has some problems which we elaborate a bit more.\n",
        "\n",
        "1. In the RL based solutions, since we use little samples to estimate the gradient at each time step, the variance would be high and it makes the process unstable and the convergence too slow. \n",
        "The SeqGAN paper attempts to speed-up the training by pre-training both the generator and discriminator as standard language models using MLE.\n",
        "\n",
        "  Also, policy gradient methods tend to converge to a local maxima, especially in cases where the state-action space is huge. Note that we have a choice between |V| actions at each time step, where V is our vocabulary (could be of the order of 100,000).\n",
        "\n",
        "2. In normal LSTM, we generate a |V|-dimensional one-hot vector y given the |V|-dimensional vector of unnormalized scores, h (the hidden state of the RNN). The standard way is to generate a vector of probabilities p using softmax. And then pick the word with the maximum probability. Instead of choosing the maximum (argmax), we can approximate it by using softmax and adding a temprature variable:\n",
        "\n",
        "  y = softmax(1/t(h + g))\n",
        "  And if t goes toward 0, it will be a good approximation of one-hot-encoding method. But this one is differentiable.\n",
        "  At first we assign a large number to t, then gradually we decrease it."
      ],
      "metadata": {
        "id": "EUjg5QS2JB0v"
      }
    }
  ]
}